% 데이터 생성
textData = [ ...
    "This is a positive statement.", ...
    "I love this product!", ...
    "I feel very happy today.", ...
    "This is a negative statement.", ...
    "I hate this product.", ...
    "I feel very sad today."];

labels = [ ...
    "positive", ...
    "positive", ...
    "positive", ...
    "negative", ...
    "negative", ...
    "negative"];

% 텍스트 데이터 전처리
documents = tokenizedDocument(textData);
enc = wordEncoding(documents);

X = doc2sequence(enc, documents);
Y = categorical(labels);

% 각 문서의 최대 길이를 계산하여 패딩할 길이를 설정
maxSeqLength = max(cellfun(@(x) size(x, 2), X));
X = padsequences(X, 2, 'PaddingValue', 0, 'Length', maxSeqLength);

% 시퀀스 데이터를 3D 배열로 변환
XTrain = cat(3, X{:});
XTrain = permute(XTrain, [1, 3, 2]); % [features, sequence, batch]

% LSTM 네트워크 아키텍처 정의
embeddingDimension = 50;
numHiddenUnits = 100;
numClasses = numel(unique(Y));

layers = [ ...
    sequenceInputLayer(size(XTrain, 1)) % 입력 크기를 특징 차원으로 설정
    lstmLayer(numHiddenUnits, 'OutputMode', 'last')
    fullyConnectedLayer(numClasses)
    softmaxLayer
    classificationLayer];

% 옵션 설정
options = trainingOptions('adam', ...
    'MaxEpochs', 10, ...
    'MiniBatchSize', 1, ...
    'SequenceLength', 'longest', ...
    'GradientThreshold', 2, ...
    'Verbose', false, ...
    'Plots', 'training-progress');

% 모델 학습
net = trainNetwork(XTrain, Y, layers, options);

% 모델 평가 (여기서는 간단히 훈련 데이터에 대한 평가)
YPred = classify(net, XTrain);
accuracy = sum(YPred == Y) / numel(Y);
disp("Training Accuracy: " + accuracy);
